{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "097d4459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable,Dict, Literal, Optional\n",
    "from langchain_ollama import ChatOllama\n",
    "import re \n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a8be92",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'qwen3:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76c5aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def booking_handler(request: str) -> str:\n",
    "    \"\"\"\n",
    "    Handles booking requests for flights and hotels.\n",
    "    \"\"\"\n",
    "    print(\"-------------------------- Booking Handler Called ----------------------------\")\n",
    "    return f\"Booking action for '{request}' has been simulated.\"\n",
    "\n",
    "def info_handler(request: str) -> str:\n",
    "    \"\"\"\n",
    "    Handles general information requests.\n",
    "    \"\"\"\n",
    "    print(\"-------------------------- Info Handler Called ----------------------------\")\n",
    "    return f\"Information request for '{request}'. Result: Simulated information retrieval.\"\n",
    "\n",
    "def unclear_handler(request: str) -> str:\n",
    "    \"\"\"Handles requests that couldn't be delegated.\"\"\"\n",
    "    return f\"Coordinator could not delegate request: '{request}'. Please clarify.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34c035a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Booking Handler Called ----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Booking action for 'some request' has been simulated.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booking_handler(\"some request\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d42f7f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Minimal Agent Abstraction -------------\n",
    "class Agent:\n",
    "    def __init__(self, name:str, description:str,tool: Callable[[str],str]):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.tool = tool\n",
    "    \n",
    "    def run(self,request:str) -> str:\n",
    "        return self.tool(request)\n",
    "    \n",
    "booking_agent = Agent(\n",
    "    name = \"Booker\",\n",
    "    description= \"Handles all the flight and hotel booking request\",\n",
    "    tool = booking_handler,\n",
    ")\n",
    "\n",
    "info_agent = Agent(\n",
    "    name= \"Info\",\n",
    "    description= \"Provdies general information and answers user questions\",\n",
    "    tool= info_handler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb31757b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Booking Handler Called ----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Booking action for 'my requst' has been simulated.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booking_agent.run(\"my requst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd081901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Booker'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booking_agent.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2dc6107",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_REGISTRY: Dict[str, Agent] = {\n",
    "    \"Booker\": booking_agent,\n",
    "    \"Info\": info_agent,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e79b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Setup\n",
    "\n",
    "llm_text = ChatOllama(\n",
    "    model= MODEL_NAME,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "llm_json = ChatOllama(\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0,\n",
    "    format = \"json\",\n",
    ")\n",
    "\n",
    "def strip_think(text:str) -> str:\n",
    "    \"\"\"\n",
    "    Remove any < think> blocks\n",
    "    \"\"\"\n",
    "    \n",
    "    return re.sub(r\"<think>.*?</think>\\s*\", \"\", text, flags=re.DOTALL | re.IGNORECASE)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1078ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to invoke chat using llm\n",
    "messages = [\n",
    "    (\"human\", \"Tell me about yourself\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "710d054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_text = llm_text.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c411fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, the user asked me to tell them about myself. I need to make sure I cover the key points without being too technical. Let me start by introducing my name, Qwen, and my role as a large language model. I should mention my development by Alibaba Cloud and my purpose to assist with various tasks.\\n\\nI should highlight my capabilities, like answering questions, creating content, and solving problems. It's important to note that I can handle multiple languages and adapt to different scenarios. Also, I need to mention my training data up to 2024, which gives me up-to-date knowledge.\\n\\nBut wait, I should avoid any technical jargon. Maybe explain that I can understand and generate text in various formats, like articles or code. Also, I should emphasize my ability to learn from interactions and improve over time. Oh, and I should invite the user to ask questions or request help with specific tasks. Let me structure this in a friendly and conversational way without using markdown. Keep it natural and engaging.\\n</think>\\n\\nHello! I'm Qwen, a large language model developed by Alibaba Cloud. My main purpose is to assist with a wide range of tasks, such as answering questions, creating content, solving problems, and more. I can understand and generate text in multiple languages, adapting to different scenarios and user needs. My training data is up to 2024, which means I can provide information and insights based on the latest knowledge available. I'm designed to be helpful, efficient, and friendly, and I'm always here to assist you with whatever you need! How can I help you today? ðŸ˜Š\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_text.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "301164b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm Qwen, a large language model developed by Alibaba Cloud. My main purpose is to assist with a wide range of tasks, such as answering questions, creating content, solving problems, and more. I can understand and generate text in multiple languages, adapting to different scenarios and user needs. My training data is up to 2024, which means I can provide information and insights based on the latest knowledge available. I'm designed to be helpful, efficient, and friendly, and I'm always here to assist you with whatever you need! How can I help you today? ðŸ˜Š\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strip_think(chat_text.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91d09d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='{\"error\": \"Forbidden\", \"message\": \"You are not allowed to access this resource.\"}', additional_kwargs={}, response_metadata={'model': 'qwen3:latest', 'created_at': '2025-10-10T15:51:11.897742899Z', 'done': True, 'done_reason': 'stop', 'total_duration': 609065589, 'load_duration': 47388843, 'prompt_eval_count': 12, 'prompt_eval_duration': 3106525, 'eval_count': 21, 'eval_duration': 558065032, 'model_name': 'qwen3:latest'}, id='run--52d5fe27-58c0-4729-b89a-57b43024ae6f-0', usage_metadata={'input_tokens': 12, 'output_tokens': 21, 'total_tokens': 33})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_json = llm_json.invoke(messages)\n",
    "chat_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bc0723b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"error\": \"Forbidden\", \"message\": \"You are not allowed to access this resource.\"}\n"
     ]
    }
   ],
   "source": [
    "print(chat_json.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b01d5514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Routing\n",
    "\n",
    "class RouteDecision(BaseModel):\n",
    "    route: Literal[\"Booker\", \"Info\", \"Unclear\"] = Field(\n",
    "        description=\"Which sub-agent should handle this request: 'Booker' for booking flights/hotels; 'Info' for general questions; 'Unclear' if ambiguous.\"\n",
    "    )\n",
    "    reason: str = Field(description=\"Brief reason for the decision.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ce1e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_route_decsion = RouteDecision(route= \"Booker\",reason=\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2466129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Booker'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_route_decsion.route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfbfa8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUTER_SYSTEM = \"\"\"You are the Coordinator. Your ONLY task:\n",
    "- Analyze the user's request and choose the proper sub-agent.\n",
    "- Never answer the user directly.\n",
    "- Return STRICT JSON with keys: route, reason.\n",
    "\n",
    "Routing rules:\n",
    "- If the request is about booking flights or hotels -> route = \"Booker\".\n",
    "- Otherwise, if it's a general information question -> route = \"Info\".\n",
    "- If it's ambiguous or cannot be routed -> route = \"Unclear\".\n",
    "\"\"\"\n",
    "\n",
    "ROUTER_HUMAN = \"\"\"User request:\n",
    "{request}\n",
    "\n",
    "Return JSON only, like:\n",
    "{{\"route\": \"Booker\", \"reason\": \"It's about hotel booking\"}}\n",
    "\"\"\"\n",
    "\n",
    "router_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", ROUTER_SYSTEM),\n",
    "        (\"human\", ROUTER_HUMAN),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa773554",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain = router_prompt | llm_json|JsonOutputParser(pydantic_object=RouteDecision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83ce99fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coordinator:\n",
    "    def __init__(self):\n",
    "        self.session_id = str(uuid.uuid4())\n",
    "\n",
    "    def route(self, request: str) -> RouteDecision:\n",
    "        decision: RouteDecision = router_chain.invoke({\"request\": request})\n",
    "        return decision\n",
    "\n",
    "    def handle(self, request: str) -> str:\n",
    "        print(f\"\\n--- Coordinator handling request: '{request}' ---\")\n",
    "        try:\n",
    "            decision = self.route(request)\n",
    "            print(f\"Routing -> {decision[\"route\"]} | Reason: {decision[\"reason\"]}\")\n",
    "\n",
    "            if decision[\"route\"] in AGENT_REGISTRY:\n",
    "                agent = AGENT_REGISTRY[decision[\"route\"]]\n",
    "                return agent.run(request)\n",
    "            else:\n",
    "                return unclear_handler(request)\n",
    "        except Exception as e:\n",
    "            return f\"An error occurred while processing your request: {e}\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27782cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Coordinator handling request: 'Book me a hotel in Paris.' ---\n",
      "Routing -> Booker | Reason: It's about hotel booking\n",
      "-------------------------- Booking Handler Called ----------------------------\n"
     ]
    }
   ],
   "source": [
    "coordinator = Coordinator()\n",
    "c = coordinator.handle(\"Book me a hotel in Paris.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c52b42af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ollama deepseek-r1 Routing Example (Auto-Flow Style) ---\n",
      "Note: Requires Ollama running locally with `deepseek-r1:7b` pulled.\n",
      "\n",
      "\n",
      "--- Coordinator handling request: 'Book me a hotel in Paris.' ---\n",
      "Routing -> Booker | Reason: It's about hotel booking\n",
      "-------------------------- Booking Handler Called ----------------------------\n",
      "Final Output A: Booking action for 'Book me a hotel in Paris.' has been simulated.\n",
      "\n",
      "--- Coordinator handling request: 'What is the highest mountain in the world?' ---\n",
      "Routing -> Info | Reason: It's a general information question about geography\n",
      "-------------------------- Info Handler Called ----------------------------\n",
      "Final Output B: Information request for 'What is the highest mountain in the world?'. Result: Simulated information retrieval.\n",
      "\n",
      "--- Coordinator handling request: 'Tell me a random fact.' ---\n",
      "Routing -> Info | Reason: The request is for a random fact, which falls under general information.\n",
      "-------------------------- Info Handler Called ----------------------------\n",
      "Final Output C: Information request for 'Tell me a random fact.'. Result: Simulated information retrieval.\n",
      "\n",
      "--- Coordinator handling request: 'Find flights to Tokyo next month.' ---\n",
      "Routing -> Booker | Reason: It's about flight booking\n",
      "-------------------------- Booking Handler Called ----------------------------\n",
      "Final Output D: Booking action for 'Find flights to Tokyo next month.' has been simulated.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"--- Ollama deepseek-r1 Routing Example (Auto-Flow Style) ---\")\n",
    "    print(\"Note: Requires Ollama running locally with `deepseek-r1:7b` pulled.\\n\")\n",
    "\n",
    "    coordinator = Coordinator()\n",
    "\n",
    "    # Example Usage\n",
    "    result_a = coordinator.handle(\"Book me a hotel in Paris.\")\n",
    "    print(f\"Final Output A: {result_a}\")\n",
    "\n",
    "    result_b = coordinator.handle(\"What is the highest mountain in the world?\")\n",
    "    print(f\"Final Output B: {result_b}\")\n",
    "\n",
    "    result_c = coordinator.handle(\"Tell me a random fact.\")  # Should go to Info\n",
    "    print(f\"Final Output C: {result_c}\")\n",
    "\n",
    "    result_d = coordinator.handle(\"Find flights to Tokyo next month.\")  # Should go to Booker\n",
    "    print(f\"Final Output D: {result_d}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e04757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
