{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab98fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.30-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.6.8-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Downloading langchain_core-0.3.78-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.32-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/saheer/.local/lib/python3.12/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/saheer/.local/lib/python3.12/site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/saheer/.local/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/saheer/.local/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/saheer/.local/lib/python3.12/site-packages (from langchain-community) (3.11.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/saheer/.local/lib/python3.12/site-packages (from langchain-community) (9.0.0)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.2-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /home/saheer/.local/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
      "Collecting openai<3.0.0,>=1.104.2 (from langchain-openai)\n",
      "  Downloading openai-2.2.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
      "  Downloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_aarch64.whl.metadata (6.7 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph)\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/saheer/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/saheer/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/saheer/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/saheer/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/saheer/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/saheer/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/saheer/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/saheer/.local/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.12.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/saheer/.local/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (24.1)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (43 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /home/saheer/.local/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph)\n",
      "  Downloading orjson-3.11.3-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/saheer/.local/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/saheer/.local/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/saheer/.local/lib/python3.12/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<3.0.0,>=1.104.2->langchain-openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<3.0.0,>=1.104.2->langchain-openai)\n",
      "  Downloading jiter-0.11.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /home/saheer/.local/lib/python3.12/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/saheer/.local/lib/python3.12/site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/saheer/.local/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/saheer/.local/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/saheer/.local/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.0.1)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/saheer/.local/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/saheer/.local/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/saheer/.local/lib/python3.12/site-packages (from requests<3,>=2->langchain) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/saheer/.local/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/saheer/.local/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1.0.0,>=0.7.0->langchain-openai)\n",
      "  Downloading regex-2025.9.18-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: httpcore==1.* in /home/saheer/.local/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/saheer/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/saheer/.local/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.0.0)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m973.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.30-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
      "Downloading langgraph-0.6.8-py3-none-any.whl (154 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.2-py3-none-any.whl (9.0 kB)\n",
      "Downloading langchain_core-0.3.78-py3-none-any.whl (449 kB)\n",
      "Downloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
      "Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Downloading langsmith-0.4.32-py3-none-any.whl (386 kB)\n",
      "Downloading openai-2.2.0-py3-none-any.whl (998 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m999.0/999.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_aarch64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.6.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (212 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.11.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (338 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading orjson-3.11.3-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (123 kB)\n",
      "Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (204 kB)\n",
      "Downloading regex-2025.9.18-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (797 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.5/797.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: xxhash, typing-inspection, typing-inspect, requests, regex, ormsgpack, orjson, marshmallow, jsonpointer, jiter, httpx-sse, distro, tiktoken, jsonpatch, dataclasses-json, pydantic-settings, openai, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langgraph-prebuilt, langchain, langgraph, langchain-community\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: pydantic-settings\n",
      "    Found existing installation: pydantic-settings 2.6.1\n",
      "    Uninstalling pydantic-settings-2.6.1:\n",
      "      Successfully uninstalled pydantic-settings-2.6.1\n",
      "Successfully installed dataclasses-json-0.6.7 distro-1.9.0 httpx-sse-0.4.2 jiter-0.11.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.27 langchain-community-0.3.30 langchain-core-0.3.78 langchain-openai-0.3.35 langchain-text-splitters-0.3.11 langgraph-0.6.8 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.9 langsmith-0.4.32 marshmallow-3.26.1 openai-2.2.0 orjson-3.11.3 ormsgpack-1.10.0 pydantic-settings-2.11.0 regex-2025.9.18 requests-2.32.5 tiktoken-0.12.0 typing-inspect-0.9.0 typing-inspection-0.4.2 xxhash-3.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain-community langchain-openai langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9a9196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain-ollama\n",
      "  Downloading langchain_ollama-0.3.10-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting ollama<1.0.0,>=0.5.3 (from langchain-ollama)\n",
      "  Downloading ollama-0.6.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.76 in /home/saheer/.local/lib/python3.12/site-packages (from langchain-ollama) (0.3.78)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/saheer/.local/lib/python3.12/site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-ollama) (0.4.32)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/saheer/.local/lib/python3.12/site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-ollama) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/saheer/.local/lib/python3.12/site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /home/saheer/.local/lib/python3.12/site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/saheer/.local/lib/python3.12/site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-ollama) (4.12.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/saheer/.local/lib/python3.12/site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-ollama) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/saheer/.local/lib/python3.12/site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-ollama) (2.9.2)\n",
      "Requirement already satisfied: httpx>=0.27 in /home/saheer/.local/lib/python3.12/site-packages (from ollama<1.0.0,>=0.5.3->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in /home/saheer/.local/lib/python3.12/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain-ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/saheer/.local/lib/python3.12/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain-ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/saheer/.local/lib/python3.12/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain-ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/saheer/.local/lib/python3.12/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/saheer/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain-ollama) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/saheer/.local/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/saheer/.local/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/saheer/.local/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/saheer/.local/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/saheer/.local/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/saheer/.local/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/saheer/.local/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (2.23.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/saheer/.local/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/saheer/.local/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (1.26.20)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/saheer/.local/lib/python3.12/site-packages (from anyio->httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain-ollama) (1.3.1)\n",
      "Downloading langchain_ollama-0.3.10-py3-none-any.whl (27 kB)\n",
      "Downloading ollama-0.6.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: ollama, langchain-ollama\n",
      "Successfully installed langchain-ollama-0.3.10 ollama-0.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aa472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# For better security, load environment variables from a .env file\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "# Make sure your OPENAI_API_KEY is set in the .env file\n",
    "\n",
    "# Initialize the Language Model (using ChatOpenAI is recommended)\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# --- Prompt 1: Extract Information ---\n",
    "prompt_extract = ChatPromptTemplate.from_template(\n",
    "   \"Extract the technical specifications from the following text:\\n\\n{text_input}\"\n",
    ")\n",
    "\n",
    "# --- Prompt 2: Transform to JSON ---\n",
    "prompt_transform = ChatPromptTemplate.from_template(\n",
    "   \"Transform the following specifications into a JSON object with 'cpu', 'memory', and 'storage' as keys:\\n\\n{specifications}\"\n",
    ")\n",
    "\n",
    "# --- Build the Chain using LCEL ---\n",
    "# The StrOutputParser() converts the LLM's message output to a simple string.\n",
    "extraction_chain = prompt_extract | llm | StrOutputParser()\n",
    "\n",
    "# The full chain passes the output of the extraction chain into the 'specifications'\n",
    "# variable for the transformation prompt.\n",
    "full_chain = (\n",
    "   {\"specifications\": extraction_chain}\n",
    "   | prompt_transform\n",
    "   | llm\n",
    "   | StrOutputParser()\n",
    ")\n",
    "\n",
    "# --- Run the Chain ---\n",
    "input_text = \"The new laptop model features a 3.5 GHz octa-core processor, 16GB of RAM, and a 1TB NVMe SSD.\"\n",
    "\n",
    "# Execute the chain with the input text dictionary.\n",
    "final_result = full_chain.invoke({\"text_input\": input_text})\n",
    "\n",
    "print(\"\\n--- Final JSON Output ---\")\n",
    "print(final_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29b4526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final JSON Output ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# No API key needed for Ollama running locally (defaults to http://localhost:11434)\n",
    "# If your Ollama server is remote, set OLLAMA_BASE_URL, e.g.:\n",
    "# os.environ[\"OLLAMA_BASE_URL\"] = \"http://your-server:11434\"\n",
    "\n",
    "# Initialize the local LLM via Ollama\n",
    "llm = ChatOllama(model=\"deepseek-r1:8b\", temperature=0)\n",
    "\n",
    "# --- Prompt 1: Extract Information ---\n",
    "prompt_extract = ChatPromptTemplate.from_template(\n",
    "   \"Extract the technical specifications from the following text:\\n\\n{text_input}\"\n",
    ")\n",
    "\n",
    "# --- Prompt 2: Transform to JSON ---\n",
    "prompt_transform = ChatPromptTemplate.from_template(\n",
    "   \"Transform the following specifications into a JSON object with 'cpu', 'memory', and 'storage' as keys:\\n\\n{specifications}\"\n",
    ")\n",
    "\n",
    "# --- Build the Chain using LCEL ---\n",
    "extraction_chain = prompt_extract | llm | StrOutputParser()\n",
    "\n",
    "full_chain = (\n",
    "   {\"specifications\": extraction_chain}\n",
    "   | prompt_transform\n",
    "   | llm\n",
    "   | StrOutputParser()\n",
    ")\n",
    "\n",
    "# --- Run the Chain ---\n",
    "input_text = \"The new laptop model features a 3.5 GHz octa-core processor, 16GB of RAM, and a 1TB NVMe SSD.\"\n",
    "final_result = full_chain.invoke({\"text_input\": input_text})\n",
    "\n",
    "print(\"\\n--- Final JSON Output ---\")\n",
    "print(final_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61b67b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = full_chain.invoke({\"text_input\": input_text})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc7ea0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"The new laptop model features a 3.5 GHz octa-core processor, 16GB of RAM, and a 1TB NVMe SSD.\"\n",
    "prompt_extract = ChatPromptTemplate.from_template(\n",
    "   \"Extract the technical specifications from the following text:\\n\\n{text_input}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de99a6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, user wants me to extract technical specs from a simple sentence about a laptop. The text is pretty straightforward - just three components mentioned clearly.\\n\\nHmm, let\\'s break this down carefully. First component is the processor: \"3.5 GHz octa-core\" that\\'s two specifications rolled into one - clock speed and core count. Second is RAM: 16GB of it. Third is storage: 1TB NVMe SSD with both capacity and interface type specified.\\n\\nThe user seems to be looking for clean, structured data extraction rather than analysis or interpretation. They probably just need the specs listed neatly without extra fluff. Maybe they\\'re comparing products or writing a review?\\n\\nI should present this in a way that\\'s easy to copy-paste while keeping all technical details intact. The processor part might confuse some users - I wonder if they\\'d prefer it split into separate clock speed and core count items? But the original phrasing combines them naturally, so better keep it as is.\\n\\nLet me organize these three specs clearly but concisely. Processor first since it\\'s often the most important component, then RAM, then storage. Should include both the descriptive part (\"octa-core\") and just the numbers for completeness.\\n</think>\\nHere are the technical specifications extracted from the text:\\n\\n1.  **Processor:** Octa-core processor with a clock speed of 3.5 GHz.\\n2.  **RAM:** 16GB.\\n3.  **Storage Drive:** 1TB NVMe SSD.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain = prompt_extract | llm | StrOutputParser()\n",
    "extraction_chain.invoke({\"text_input\": input_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "838a3e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final JSON Output ---\n",
      "{\n",
      "\n",
      "\n",
      "\"cpu\": \"Octa-core, 3.5 GHz\",\n",
      "\"memory\": \"16GB\",\n",
      "\"storage\": \"1TB NVMe SSD\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# pip install langchain-ollama langchain-core\n",
    "\n",
    "import re\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# --- LLMs (same model, different configs) ---\n",
    "# Plain responses (we'll still strip <think> just in case)\n",
    "\n",
    "llm = ChatOllama(model=\"deepseek-r1:8b\", temperature=0)\n",
    "# Enforce strict JSON for the second step\n",
    "llm_json = ChatOllama(model=\"deepseek-r1:8b\", temperature=0, format=\"json\")\n",
    "\n",
    "# --- Helpers ---\n",
    "def strip_think(text: str) -> str:\n",
    "    # Removes any <think>...</think> blocks DeepSeek might include\n",
    "    return re.sub(r\"<think>.*?</think>\\s*\", \"\", text, flags=re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "stripper = RunnableLambda(strip_think)\n",
    "\n",
    "# --- Prompt 1: Extract Information ---\n",
    "prompt_extract = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a precise information extractor. Do NOT reveal your reasoning or chain-of-thought.\"),\n",
    "    (\"human\", \"Extract the technical specifications from the following text:\\n\\n{text_input}\")\n",
    "])\n",
    "\n",
    "# --- Prompt 2: Transform to JSON ---\n",
    "prompt_transform = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You convert data to STRICT JSON. Do NOT reveal reasoning. Output JSON only, no extra text.\"),\n",
    "    (\"human\", \"Transform the following specifications into a JSON object with keys exactly 'cpu', 'memory', and 'storage':\\n\\n{specifications}\")\n",
    "])\n",
    "\n",
    "# --- Build Chains ---\n",
    "extraction_chain = prompt_extract | llm | StrOutputParser() | stripper\n",
    "\n",
    "full_chain = (\n",
    "    {\"specifications\": extraction_chain}\n",
    "    | prompt_transform\n",
    "    | llm_json                 # format=\"json\" enforces JSON-only output\n",
    "    | StrOutputParser()\n",
    "    | stripper\n",
    ")\n",
    "\n",
    "# --- Run ---\n",
    "input_text = \"The new laptop model features a 3.5 GHz octa-core processor, 16GB of RAM, and a 1TB NVMe SSD.\"\n",
    "final_result = full_chain.invoke({\"text_input\": input_text})\n",
    "\n",
    "print(\"\\n--- Final JSON Output ---\")\n",
    "print(final_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf54d655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
